{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Problem: Region Segmentation Using Traditional Techniques  (3 Marks) \\\n",
        "i. Implement a region-based segmentation method (e.g., thresholding, edge\n",
        "detection) to segment the mask regions for faces identified as \"with mask.\" \\\n",
        "ii. Visualize and evaluate the segmentation results."
      ],
      "metadata": {
        "id": "Z2MhcgjIKwWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qxpMo9izMibo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19e88e24-bdc8-4a16-fc43-e6e191377b8e"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "P5gEqiXEnNpC"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.cluster import KMeans\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = \"/content/drive/MyDrive/Segmentation Dataset/1\"\n",
        "cropped_images_dir = os.path.join(base_dir, \"face_crop\")\n",
        "segmented_images_dir = os.path.join(base_dir, \"face_crop_segmentation\")\n",
        "normal_images_dir = os.path.join(base_dir, \"img\")\n",
        "json_path = os.path.join(base_dir, \"mapped_images.json\")"
      ],
      "metadata": {
        "id": "dstHXIsmxFxT"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load JSON mapping\n",
        "with open(json_path, 'r') as json_file:\n",
        "    mapped_images = json.load(json_file)"
      ],
      "metadata": {
        "id": "qYLHPqlLwta5"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image):\n",
        "    if len(image.shape) == 3:  # Convert color image to grayscale if needed\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        gray = image  # Already grayscale\n",
        "\n",
        "    gray = cv2.normalize(gray, None, 0, 255, cv2.NORM_MINMAX)  # Ensure proper range\n",
        "    gray = np.uint8(gray)  # Convert to uint8\n",
        "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "    if gray.dtype == np.uint8:\n",
        "        gray = cv2.equalizeHist(gray)  # Apply histogram equalization safely\n",
        "    return gray\n"
      ],
      "metadata": {
        "id": "o8Bo_qzQPSWr"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ---------------------------------------\n",
        "# METHOD 1: OTSU’S THRESHOLDING + EDGES\n"
      ],
      "metadata": {
        "id": "0-rDWbjZ7Iol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def segment_otsu(image):\n",
        "    gray = preprocess_image(image)\n",
        "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    return cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, np.ones((3, 3), np.uint8))\n"
      ],
      "metadata": {
        "id": "jfinwpnD7ICn"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# METHOD 2: ADAPTIVE THRESHOLDING"
      ],
      "metadata": {
        "id": "Mjxz9Dra7PkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def segment_adaptive_threshold(image):\n",
        "    gray = preprocess_image(image)\n",
        "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
        "    return cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, np.ones((3, 3), np.uint8))\n"
      ],
      "metadata": {
        "id": "UGnDdFKA7IAA"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# METHOD 3: WATERSHED SEGMENTATION"
      ],
      "metadata": {
        "id": "dKi4t-aB7QA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def segment_watershed(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "    # Ensure the image is uint8 before thresholding\n",
        "    blurred = cv2.normalize(blurred, None, 0, 255, cv2.NORM_MINMAX)\n",
        "    blurred = np.uint8(blurred)\n",
        "\n",
        "    _, binary = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Noise removal (Morphology)\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    sure_bg = cv2.dilate(binary, kernel, iterations=3)\n",
        "\n",
        "    # Foreground area\n",
        "    dist_transform = cv2.distanceTransform(binary, cv2.DIST_L2, 5)\n",
        "\n",
        "    # Normalize and convert dist_transform to uint8\n",
        "    dist_transform = cv2.normalize(dist_transform, None, 0, 255, cv2.NORM_MINMAX)\n",
        "    dist_transform = np.uint8(dist_transform)\n",
        "\n",
        "    _, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
        "\n",
        "    # Ensure both have the same dtype\n",
        "    sure_fg = np.uint8(sure_fg)\n",
        "    sure_bg = np.uint8(sure_bg)\n",
        "\n",
        "    # Identify unknown regions\n",
        "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
        "\n",
        "    # Marker labelling\n",
        "    markers = cv2.connectedComponents(sure_fg)[1] + 1\n",
        "    markers[unknown == 255] = 0\n",
        "\n",
        "    # Convert markers to CV_32SC1 before passing to watershed\n",
        "    markers = markers.astype(np.int32) # Ensure markers is of type int32\n",
        "\n",
        "    # Apply Watershed\n",
        "    image_color = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR) if len(image.shape) == 2 else image\n",
        "    cv2.watershed(image_color, markers)\n",
        "\n",
        "    # Return the segmented mask\n",
        "    return np.uint8(markers > 1) * 255"
      ],
      "metadata": {
        "id": "7immfGHQ-5TE"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# METHOD 4: K-MEANS CLUSTERING"
      ],
      "metadata": {
        "id": "9cHMQV0m7Qev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def segment_kmeans(image, k=3):\n",
        "    pixel_values = image.reshape((-1, 3)).astype(np.float32)\n",
        "    _, labels, centers = cv2.kmeans(pixel_values, k, None, (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0), 10, cv2.KMEANS_RANDOM_CENTERS)\n",
        "    segmented_image = centers[labels.flatten()].reshape(image.shape)\n",
        "    gray = cv2.cvtColor(np.uint8(segmented_image), cv2.COLOR_BGR2GRAY)\n",
        "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    return binary"
      ],
      "metadata": {
        "id": "DhDVh7Il7H6x"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# METHOD 5: GRABCUT ALGORITHM"
      ],
      "metadata": {
        "id": "rPaj4m3G7knP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def segment_grabcut(image):\n",
        "    mask = np.zeros(image.shape[:2], np.uint8)\n",
        "    bgd_model = np.zeros((1, 65), np.float64)\n",
        "    fgd_model = np.zeros((1, 65), np.float64)\n",
        "    rect = (10, 10, image.shape[1] - 20, image.shape[0] - 20)\n",
        "    cv2.grabCut(image, mask, rect, bgd_model, fgd_model, 7, cv2.GC_INIT_WITH_RECT)\n",
        "    return np.where((mask == 2) | (mask == 0), 0, 255).astype('uint8')\n"
      ],
      "metadata": {
        "id": "vhsAClhL_J7o"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------\n",
        "# Evaluation Metrics"
      ],
      "metadata": {
        "id": "X55hzKKn7y-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_iou(segmented_mask, ground_truth):\n",
        "    intersection = np.logical_and(segmented_mask, ground_truth).sum()\n",
        "    union = np.logical_or(segmented_mask, ground_truth).sum()\n",
        "    return intersection / union if union else 0\n",
        "\n",
        "def dice_coefficient(segmented_mask, ground_truth):\n",
        "    intersection = np.logical_and(segmented_mask, ground_truth).sum()\n",
        "    return (2 * intersection) / (segmented_mask.sum() + ground_truth.sum()) if segmented_mask.sum() + ground_truth.sum() else 0\n",
        "\n",
        "def compute_metrics(segmented_mask, ground_truth):\n",
        "    segmented_mask = segmented_mask.flatten()\n",
        "    ground_truth = ground_truth.flatten()\n",
        "    return precision_score(ground_truth, segmented_mask, average='macro'), recall_score(ground_truth, segmented_mask, average='macro'), f1_score(ground_truth, segmented_mask, average='macro')\n",
        "\n",
        "    precision = precision_score(ground_truth, segmented_mask, average='macro')\n",
        "    recall = recall_score(ground_truth, segmented_mask, average='macro')\n",
        "    f1 = f1_score(ground_truth, segmented_mask, average='macro')\n",
        "\n",
        "    return precision, recall, f1\n"
      ],
      "metadata": {
        "id": "-GY5KL1Rxokc"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ----------------------------\n",
        "# Visualization\n",
        "\n"
      ],
      "metadata": {
        "id": "jmoZyYXp77WO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def visualize_segmentation(original, segmented, ground_truth, title=\"Segmentation Result\"):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(\"Original Image\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(segmented, cmap=\"gray\")\n",
        "    plt.title(\"Segmented Mask\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(ground_truth, cmap=\"gray\")\n",
        "    plt.title(\"Ground Truth Mask\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.suptitle(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "gWNid_f44E8f"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ----------------------------\n",
        "# Process Images and Evaluate\n"
      ],
      "metadata": {
        "id": "T-ItD5Cs7_UV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskDataset(Dataset):\n",
        "    def __init__(self, mapped_images, img_height, img_width):\n",
        "        self.mapped_images = mapped_images\n",
        "        self.img_height = img_height\n",
        "        self.img_width = img_width\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.mapped_images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, mask_path = self.mapped_images[idx]\n",
        "        # Load and resize image\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            raise FileNotFoundError(f\"⚠️ Image not found: {img_path}\")\n",
        "        img = cv2.resize(img, (self.img_width, self.img_height))\n",
        "        img = img.astype(np.float32) / 255.0\n",
        "        img = np.transpose(img, (2, 0, 1))  # (C, H, W)\n",
        "\n",
        "        # Load and resize mask\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if mask is None:\n",
        "            raise FileNotFoundError(f\"⚠️ Mask not found: {mask_path}\")\n",
        "        mask = cv2.resize(mask, (self.img_width, self.img_height))\n",
        "        mask = np.where(mask > 0, 1, 0).astype(np.uint8)\n",
        "        mask = np.expand_dims(mask, axis=0)  # (1, H, W)\n",
        "\n",
        "        return torch.tensor(img, dtype=torch.float32), torch.tensor(mask, dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "OQ9ub3bDAKOL"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "RANDOM_SEED = 42\n",
        "random.seed(RANDOM_SEED)\n",
        "\n",
        "# Load mapped images from JSON\n",
        "with open(\"/content/drive/MyDrive/Segmentation Dataset/1/mapped_images.json\", \"r\") as f:\n",
        "    mapped_images = json.load(f)\n",
        "\n",
        "# Define image dimensions and channels\n",
        "IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS = 256, 256, 3\n",
        "BATCH_SIZE = 32\n",
        "# Initialize dataset\n",
        "dataset = MaskDataset(mapped_images, IMG_HEIGHT, IMG_WIDTH)\n",
        "\n",
        "# Get all indices\n",
        "indices = list(range(len(dataset)))\n",
        "\n",
        "# Split dataset: 70% training, 30% validation\n",
        "train_indices, val_indices = train_test_split(indices, test_size=0.3, random_state=RANDOM_SEED)\n",
        "\n",
        "# Create subsets\n",
        "train_dataset = Subset(dataset, train_indices)\n",
        "val_dataset = Subset(dataset, val_indices)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "print(f\"✅ Data ready! Train size: {len(train_indices)}, Validation size: {len(val_indices)}\")\n",
        "\n",
        "# Define segmentation functions (Otsu, Adaptive, Watershed, GrabCut, K-Means)\n",
        "# Assuming they are defined earlier in the script\n",
        "\n",
        "def evaluate_segmentation():\n",
        "    results = {\"Otsu\": [], \"Adaptive\": [], \"Watershed\": [], \"GrabCut\": [], \"K-Means\": []}\n",
        "    count = 0\n",
        "\n",
        "    for batch in val_loader:\n",
        "        count += 1\n",
        "        if count > 2:  # Limit to two batches\n",
        "            break\n",
        "\n",
        "        face_crops, ground_truth_masks = batch  # Assuming dataset returns (image, mask) pairs\n",
        "\n",
        "        for i in range(face_crops.shape[0]):\n",
        "            # Convert tensor to numpy image (assuming tensor shape is [C, H, W])\n",
        "            face_crop = face_crops[i].numpy().transpose(1, 2, 0)\n",
        "            face_crop = (face_crop * 255).astype(np.uint8)  # Rescale & convert to uint8 if necessary\n",
        "\n",
        "            # Convert mask to binary format\n",
        "            ground_truth_mask = ground_truth_masks[i].numpy()\n",
        "            ground_truth_mask = (ground_truth_mask > 0.5).astype(np.uint8) * 255  # Ensure mask is in [0, 255]\n",
        "\n",
        "            # Perform segmentation\n",
        "            methods = {\n",
        "                \"Otsu\": segment_otsu(face_crop),\n",
        "                \"Adaptive\": segment_adaptive_threshold(face_crop),\n",
        "                \"Watershed\": segment_watershed(face_crop),\n",
        "                \"GrabCut\": segment_grabcut(face_crop),\n",
        "                \"K-Means\": segment_kmeans(face_crop)\n",
        "            }\n",
        "\n",
        "            # Evaluate each segmentation method\n",
        "            for method, seg_mask in methods.items():\n",
        "                iou_score = calculate_iou(seg_mask, ground_truth_mask)\n",
        "                dice_score = dice_coefficient(seg_mask, ground_truth_mask)\n",
        "                precision, recall, f1 = compute_metrics(seg_mask, ground_truth_mask)\n",
        "\n",
        "                results[method].append({\n",
        "                    \"IoU\": iou_score, \"Dice\": dice_score,\n",
        "                    \"Precision\": precision, \"Recall\": recall, \"F1\": f1\n",
        "                })\n",
        "\n",
        "    return results\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGXjZkU-_ri5",
        "outputId": "7551ceac-ef0c-488f-d786-d5ddb02479f8"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Data ready! Train size: 6567, Validation size: 2815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run evaluation\n",
        "overall_results = evaluate_segmentation()\n",
        "\n",
        "# Print overall metrics\n",
        "for method, metrics in overall_results.items():\n",
        "    avg_iou = np.mean([m[\"IoU\"] for m in metrics])\n",
        "    avg_dice = np.mean([m[\"Dice\"] for m in metrics])\n",
        "    avg_precision = np.mean([m[\"Precision\"] for m in metrics])\n",
        "    avg_recall = np.mean([m[\"Recall\"] for m in metrics])\n",
        "    avg_f1 = np.mean([m[\"F1\"] for m in metrics])\n",
        "\n",
        "    print(f\"Method: {method}\")\n",
        "    print(f\"Avg IoU: {avg_iou:.4f}, Avg Dice: {avg_dice:.4f}\")\n",
        "    print(f\"Avg Precision: {avg_precision:.4f}, Avg Recall: {avg_recall:.4f}, Avg F1-Score: {avg_f1:.4f}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWmEvy9AJplo",
        "outputId": "eef6aff5-b6cd-4755-e051-44674684f90a"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Method: Otsu\n",
            "Avg IoU: 0.2952, Avg Dice: 0.0017\n",
            "Avg Precision: 0.4836, Avg Recall: 0.4880, Avg F1-Score: 0.4746\n",
            "\n",
            "Method: Adaptive\n",
            "Avg IoU: 0.3225, Avg Dice: 0.0019\n",
            "Avg Precision: 0.4561, Avg Recall: 0.4645, Avg F1-Score: 0.3927\n",
            "\n",
            "Method: Watershed\n",
            "Avg IoU: 0.2300, Avg Dice: 0.0012\n",
            "Avg Precision: 0.4723, Avg Recall: 0.4997, Avg F1-Score: 0.4688\n",
            "\n",
            "Method: GrabCut\n",
            "Avg IoU: 0.4823, Avg Dice: 0.0024\n",
            "Avg Precision: 0.6987, Avg Recall: 0.6888, Avg F1-Score: 0.6617\n",
            "\n",
            "Method: K-Means\n",
            "Avg IoU: 0.2654, Avg Dice: 0.0015\n",
            "Avg Precision: 0.4682, Avg Recall: 0.4718, Avg F1-Score: 0.4379\n",
            "\n"
          ]
        }
      ]
    }
  ]
}